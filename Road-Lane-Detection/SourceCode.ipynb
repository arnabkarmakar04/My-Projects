{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Image Processing Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "       \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    if lines is None:\n",
    "        return\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., g=0.):\n",
    "    return cv2.addWeighted(initial_img,a, img, b, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color_space(img, color_space='HSV'):\n",
    "    if color_space == 'HSV':\n",
    "        space = cv2.COLOR_RGB2HSV\n",
    "    if color_space == 'HLS':\n",
    "        space = cv2.COLOR_RGB2HLS\n",
    "    if color_space == 'LAB':\n",
    "        space = cv2.COLOR_RGB2LAB\n",
    "    else:\n",
    "        space = None\n",
    "    if space is not None:\n",
    "        return cv2.cvtColor(img, space)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_line(img, lower, upper):\n",
    "    mask = cv2.inRange(img, np.array(lower, dtype=np.uint8), np.array(upper, dtype=np.uint8))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Region of Interest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices_for_img(img):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    if (width, height) == (960, 540):\n",
    "        region_bottom_left = (130 ,height - 1)\n",
    "        region_top_left = (410, 330)\n",
    "        region_top_right = (650, 350)\n",
    "        region_bottom_right = (width - 30, height - 1)\n",
    "    else:\n",
    "        region_bottom_left = (200 , 680)\n",
    "        region_top_left = (600, 450)\n",
    "        region_top_right = (750, 450)\n",
    "        region_bottom_right = (1100, 650)\n",
    "    return np.array([[region_bottom_left, region_top_left, region_top_right, region_bottom_right]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        ignore_mask_color = (255,) * img.shape[2]\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    vert = get_vertices_for_img(img)\n",
    "    cv2.fillPoly(mask, vert, ignore_mask_color)\n",
    "    return cv2.bitwise_and(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Lane line detection functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_lines_formula(lines):\n",
    "    xs, ys = [], []\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            xs.extend([x1, x2])\n",
    "            ys.extend([y1, y2])\n",
    "    if len(xs) == 0:\n",
    "        return 0, 0\n",
    "    slope, intercept, _, _, _ = stats.linregress(xs, ys)\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_full_lines(img, slope, intercept, color, thickness):\n",
    "    if slope == 0 and intercept == 0:\n",
    "        return\n",
    "    y = np.array([int(img.shape[0]*0.63), img.shape[0]-1], 'float')\n",
    "    x = (y - intercept) / slope\n",
    "    cv2.line(img, (int(x[0]), int(y[0])), (int(x[1]), int(y[1])), color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Process single image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # Convert color spaces\n",
    "    LAB_img = change_color_space(image,'LAB')\n",
    "    HLS_img = change_color_space(image,'HLS')\n",
    "\n",
    "    # Extract yellow and white lines\n",
    "    yellow_lines = extract_line(LAB_img, [100,100,150], [220,180,255])\n",
    "    white_lines = extract_line(HLS_img, [0,200,0], [180,255,255])\n",
    "\n",
    "    # Morphological operations for white lines\n",
    "    white_lines = cv2.dilate(white_lines, np.ones((5,5), np.uint8), iterations=2)\n",
    "    white_lines = cv2.erode(white_lines, np.ones((5,5), np.uint8), iterations=2)\n",
    "    white_lines = cv2.dilate(white_lines, np.ones((5,5), np.uint8), iterations=1)\n",
    "    \n",
    "    # Combine masks and apply to image\n",
    "    line_mask = yellow_lines + white_lines\n",
    "    masked_img = np.copy(image)\n",
    "    masked_img = cv2.dilate(masked_img, np.ones((5,5), np.uint8), iterations=2)\n",
    "    masked_img = cv2.erode(masked_img, np.ones((5,5), np.uint8), iterations=2)\n",
    "    masked_img = cv2.dilate(masked_img, np.ones((5,5), np.uint8), iterations=1)\n",
    "    masked_img[line_mask!=255] = [0,0,0]\n",
    "    \n",
    "    # Region of interest and Hough Transform\n",
    "    cleaned_img = region_of_interest(masked_img)\n",
    "    hough_img, lines = hough_lines(grayscale(cleaned_img), 1, np.pi/180, 17, 7, 0)\n",
    "    \n",
    "    # Separate left/right lanes\n",
    "    overlay = np.zeros_like(image)\n",
    "    right_lanes, left_lanes = [], []\n",
    "    epsilon = 0.5\n",
    "    middle_x = image.shape[1]/2\n",
    "    \n",
    "    for line in lines if lines is not None else []:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if (x2-x1)!=0 and (y2-y1)!=0:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if abs(slope) > epsilon:\n",
    "                if slope > 0 and middle_x < x1 < x2:\n",
    "                    right_lanes.append([[x1,y1,x2,y2]])\n",
    "                elif slope < 0 and x1 < x2 < middle_x:\n",
    "                    left_lanes.append([[x1,y1,x2,y2]])\n",
    "\n",
    "    # Draw full lanes   \n",
    "    if len(right_lanes) > 0:\n",
    "        slope, intercept = find_lane_lines_formula(right_lanes)\n",
    "        draw_full_lines(overlay, slope, intercept, [0,0,255], 10)\n",
    "    if len(left_lanes) > 0:\n",
    "        slope, intercept = find_lane_lines_formula(left_lanes)\n",
    "        draw_full_lines(overlay, slope, intercept, [0,0,255], 10)\n",
    "    \n",
    "    # Overlay on original image\n",
    "    result = weighted_img(overlay, image, a=0.8, b=1., g=0.)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"Test_Images/\"\n",
    "output_folder = \"Test_Images_Output\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Process images***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_img in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, name_img)\n",
    "    image = mpimg.imread(image_path)\n",
    "    \n",
    "    result, masked_img, hough_img, yellow_lines, white_lines = process_image(image)\n",
    "    \n",
    "    # Show step-by-step visualizations\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original RGB')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(masked_img)\n",
    "    plt.title('Masked Image')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(result)\n",
    "    plt.title('Final Lane Overlay')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(yellow_lines, cmap='gray')\n",
    "    plt.title('Yellow Mask')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(white_lines, cmap='gray')\n",
    "    plt.title('White Mask')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(hough_img, cmap='gray')\n",
    "    plt.title('Hough Lines Reconstruction')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save final overlay\n",
    "    Image.fromarray(result).save(os.path.join(output_folder, name_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Process video***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_folder = \"Test_Videos/\"\n",
    "video_output_folder = \"Test_Videos_Output\"\n",
    "os.makedirs(video_output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_name in os.listdir(video_input_folder):\n",
    "    input_path = os.path.join(video_input_folder, video_name)\n",
    "    output_path = os.path.join(video_output_folder, video_name)\n",
    "    clip = VideoFileClip(input_path)\n",
    "    processed_clip = clip.fl_image(lambda frame: process_image(frame)[0])\n",
    "    processed_clip.write_videofile(output_path, audio=False)\n",
    "    print(f\"Processed video saved at: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
